{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Soumik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Soumik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import math \n",
    "from math import sqrt\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=[] #corpus\n",
    "tokens_in_doc=[]\n",
    "\n",
    "\n",
    "def __remove_punctuation(text):\n",
    "\n",
    "        message = []\n",
    "        for x in text:\n",
    "            if x in string.punctuation:\n",
    "                message.append(' ')\n",
    "            else:\n",
    "                message.append(x)\n",
    "                \n",
    "        message = ''.join(message)\n",
    "\n",
    "        return message\n",
    "\n",
    "def __remove_stopwords(text):\n",
    "\n",
    "    words= []\n",
    "\n",
    "    for x in text.split():\n",
    "\n",
    "        x=x.lower()\n",
    "\n",
    "        if x in stopwords.words('english'):\n",
    "            pass\n",
    "        \n",
    "        elif x.isnumeric():\n",
    "            pass\n",
    "\n",
    "        else:\n",
    "            # stemmer = nltk.stem.PorterStemmer()\n",
    "            # x = stemmer.stem(x)\n",
    "            lemma = nltk.wordnet.WordNetLemmatizer()   #lemmatization\n",
    "            x=lemma.lemmatize(x)\n",
    "            words.append(x)\n",
    "\n",
    "    return words\n",
    "\n",
    "def token_words(text):\n",
    "\n",
    "    message = __remove_punctuation(text)\n",
    "    words = __remove_stopwords(message)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 101.0.4951\n",
      "Get LATEST chromedriver version for 101.0.4951 google-chrome\n",
      "Driver [C:\\Users\\Soumik\\.wdm\\drivers\\chromedriver\\win32\\101.0.4951.41\\chromedriver.exe] found in cache\n",
      "C:\\Users\\Soumik\\AppData\\Local\\Temp\\ipykernel_9700\\3352578384.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install())\n"
     ]
    }
   ],
   "source": [
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "\n",
    "urls = []\n",
    "titles = []\n",
    "\n",
    "\n",
    "with open('lt_url.txt') as f:\n",
    "\n",
    "    urls = f.readlines()\n",
    "\n",
    "with open('lt_title.txt') as f:\n",
    "\n",
    "    titles = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_1=urls[0]\n",
    "\n",
    "driver.get(url_1)\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "html = driver.page_source\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "ques = soup.find(\"div\", {\"class\": \"content__u3I1 question-content__JfgR\"})\n",
    "\n",
    "problem_text_html = ques.findChild(\"div\", recursive=False).encode('utf-8')\n",
    "\n",
    "problem_text_html = problem_text_html.decode('ascii', 'ignore')\n",
    "\n",
    "with open(\"problem_1.txt\", \"w+\") as f:\n",
    "    f.write(problem_text_html)\n",
    "\n",
    "first_problem_text = ques.get_text()\n",
    "\n",
    "first_problem_text = first_problem_text + \" \" + titles[0]\n",
    "\n",
    "doc.append([first_problem_text])\n",
    "\n",
    "first_problem_text = token_words(first_problem_text)\n",
    "\n",
    "tokens_in_doc.append(first_problem_text)\n",
    "\n",
    "total = set(first_problem_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "652\n",
      "727\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "\n",
    "for url in urls:\n",
    "\n",
    "    try:\n",
    "\n",
    "        if(cnt==0):\n",
    "            cnt+=1\n",
    "            continue\n",
    "\n",
    "        driver.get(url)\n",
    "\n",
    "        time.sleep(5)\n",
    "\n",
    "\n",
    "        html = driver.page_source\n",
    "\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        ques = soup.find(\"div\", {\"class\": \"content__u3I1 question-content__JfgR\"})\n",
    "\n",
    "        if(ques is None):\n",
    "            print(cnt, url)\n",
    "            titles.pop(cnt)\n",
    "            continue\n",
    "\n",
    "        problem_text_html = ques.findChild(\"div\", recursive=False).encode('utf-8')\n",
    "\n",
    "        problem_text_html = problem_text_html.decode('ascii', 'ignore')\n",
    "\n",
    "        with open(\"problem_\"+str(cnt+1)+\".txt\", \"w+\") as f:\n",
    "            f.write(problem_text_html)\n",
    "\n",
    "        problem_text = ques.get_text()\n",
    "\n",
    "        problem_text = problem_text + \" \" + titles[cnt]\n",
    "        \n",
    "        doc.append([problem_text])\n",
    "\n",
    "        problem_text = token_words(problem_text)\n",
    "\n",
    "        tokens_in_doc.append(problem_text)\n",
    "\n",
    "        total = total.union(set(problem_text))\n",
    "\n",
    "        cnt += 1\n",
    "\n",
    "    except:\n",
    "        print(cnt)\n",
    "        titles.pop(cnt)\n",
    "        continue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>red</th>\n",
       "      <th>mean</th>\n",
       "      <th>priority</th>\n",
       "      <th>protected</th>\n",
       "      <th>mountain</th>\n",
       "      <th>ascii</th>\n",
       "      <th>orderly</th>\n",
       "      <th>shop</th>\n",
       "      <th>knight</th>\n",
       "      <th>deck</th>\n",
       "      <th>...</th>\n",
       "      <th>light</th>\n",
       "      <th>gnid</th>\n",
       "      <th>cnti</th>\n",
       "      <th>durationi</th>\n",
       "      <th>ghij</th>\n",
       "      <th>flood</th>\n",
       "      <th>principle</th>\n",
       "      <th>plank</th>\n",
       "      <th>false</th>\n",
       "      <th>attribute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 6010 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   red  mean  priority  protected  mountain  ascii  orderly  shop  knight  \\\n",
       "0    0     0         0          0         0      0        0     0       0   \n",
       "\n",
       "   deck  ...  light  gnid  cnti  durationi  ghij  flood  principle  plank  \\\n",
       "0     0  ...      0     0     0          0     0      0          0      0   \n",
       "\n",
       "   false  attribute  \n",
       "0      0          0  \n",
       "\n",
       "[1 rows x 6010 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordDictA = dict.fromkeys(total, 0) \n",
    "\n",
    "for word in first_problem_text:\n",
    "    wordDictA[word]+=1\n",
    "\n",
    "df=pd.DataFrame([wordDictA])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt2=0\n",
    "\n",
    "for each_doc in tokens_in_doc:\n",
    "    \n",
    "    if(cnt2==0):\n",
    "        cnt2+=1\n",
    "        continue\n",
    "\n",
    "    wordDictB = dict.fromkeys(total, 0)\n",
    "    for word in each_doc:\n",
    "        wordDictB[word]+=1\n",
    "    \n",
    "    df = df.append([wordDictB], ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTF(wordDict, doc):\n",
    "    tfDict = {}\n",
    "    corpusCount = len(doc)\n",
    "    for word, count in wordDict.items():\n",
    "        tfDict[word] = count/float(corpusCount)\n",
    "    return(tfDict)\n",
    "#running our sentences through the tf function:\n",
    "\n",
    "tf = pd.DataFrame([computeTF(df.iloc[0], tokens_in_doc[0])])\n",
    "\n",
    "for i in range(1,cnt):\n",
    "    tf_i = computeTF(df.iloc[i], tokens_in_doc[i])\n",
    "    tf=tf.append([tf_i], ignore_index=True)    #Converting to dataframe for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>red</th>\n",
       "      <th>mean</th>\n",
       "      <th>priority</th>\n",
       "      <th>protected</th>\n",
       "      <th>mountain</th>\n",
       "      <th>ascii</th>\n",
       "      <th>orderly</th>\n",
       "      <th>shop</th>\n",
       "      <th>knight</th>\n",
       "      <th>deck</th>\n",
       "      <th>...</th>\n",
       "      <th>light</th>\n",
       "      <th>gnid</th>\n",
       "      <th>cnti</th>\n",
       "      <th>durationi</th>\n",
       "      <th>ghij</th>\n",
       "      <th>flood</th>\n",
       "      <th>principle</th>\n",
       "      <th>plank</th>\n",
       "      <th>false</th>\n",
       "      <th>attribute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.549718</td>\n",
       "      <td>1.367637</td>\n",
       "      <td>2.92993</td>\n",
       "      <td>2.92993</td>\n",
       "      <td>2.53199</td>\n",
       "      <td>2.189567</td>\n",
       "      <td>3.23096</td>\n",
       "      <td>2.53199</td>\n",
       "      <td>2.753838</td>\n",
       "      <td>2.92993</td>\n",
       "      <td>...</td>\n",
       "      <td>3.23096</td>\n",
       "      <td>3.23096</td>\n",
       "      <td>3.23096</td>\n",
       "      <td>3.23096</td>\n",
       "      <td>3.23096</td>\n",
       "      <td>2.92993</td>\n",
       "      <td>2.6289</td>\n",
       "      <td>3.23096</td>\n",
       "      <td>0.882655</td>\n",
       "      <td>2.753838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 6010 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        red      mean  priority  protected  mountain     ascii  orderly  \\\n",
       "0  1.549718  1.367637   2.92993    2.92993   2.53199  2.189567  3.23096   \n",
       "\n",
       "      shop    knight     deck  ...    light     gnid     cnti  durationi  \\\n",
       "0  2.53199  2.753838  2.92993  ...  3.23096  3.23096  3.23096    3.23096   \n",
       "\n",
       "      ghij    flood  principle    plank     false  attribute  \n",
       "0  3.23096  2.92993     2.6289  3.23096  0.882655   2.753838  \n",
       "\n",
       "[1 rows x 6010 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def computeIDF(data):\n",
    "\n",
    "    idfDict = {}\n",
    "    N = cnt\n",
    "    \n",
    "    idfDict = dict.fromkeys(data.keys(), 0)\n",
    "\n",
    "    for key in data.keys():\n",
    "\n",
    "        count= (df[key]>0).sum()\n",
    "\n",
    "        if(count!=0):\n",
    "            idfDict[key] = math.log10(N / (float(count)))   #if some  word occurs in all document, this will return 0, implying that it is least rare \n",
    "        else:\n",
    "            idfDict[key] = 0\n",
    "        \n",
    "    return(idfDict)\n",
    "\n",
    "idfs = computeIDF(df)\n",
    "\n",
    "idf_df=pd.DataFrame([idfs])\n",
    "\n",
    "idf_df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = pd.DataFrame(tf.values*idf_df.values, columns=tf.columns, index=tf.index)\n",
    "\n",
    "keywords = tf_idf.columns.values.tolist()\n",
    "\n",
    "with open('keywords.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    f.write(' '.join(map(str, keywords)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "magnitude=[]\n",
    "\n",
    "def calculateMagnitude(v):\n",
    "    magnitude = 0\n",
    "    for j in range(0, len(tf_idf.columns)):\n",
    "        magnitude += pow((v[j]), 2.0)\n",
    "    return sqrt(magnitude * 1.0)\n",
    "\n",
    "ls = tf_idf.values.tolist()\n",
    "\n",
    "for i in range(0,cnt):\n",
    "    magnitude.append(calculateMagnitude(ls[i]))\n",
    "\n",
    "with open('magnitude.txt', 'w') as f:\n",
    "    f.write(' '.join(map(str, magnitude)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "arr = tf_idf.to_numpy()\n",
    "\n",
    "for i in range(0,cnt):\n",
    "    for j in range(0,len(tf_idf.columns)):\n",
    "        if(arr[i][j]!=0):\n",
    "            with open('tf_idf.txt', 'a') as f:\n",
    "                f.write(str(i)+' '+str(j)+' '+str(arr[i][j])+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_df.to_csv(r'./idf.txt', header=None, index=None, sep=' ',mode='w')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "29d7bbd736e5f89b70e81a0eb899818172636dd18be77104559aa18680732d47"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
